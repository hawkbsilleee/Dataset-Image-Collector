{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list =[]\n",
    "x = open(\"multimedia.txt\", \"r\")\n",
    "letters = 'https://www.inaturalist.org/photos/' # \"ro\" would match \"copper\" and \"word\"\n",
    "for line in x:\n",
    "    for word in line.split():\n",
    "        if all(l in word.lower() for l in letters): # could optimize with sets if needed\n",
    "            list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "x = open(\"multimedia.txt\", \"r\")\n",
    "letters = 'https://static.inaturalist.org/photos/' # \"ro\" would match \"copper\" and \"word\"\n",
    "for line in x:\n",
    "    for word in line.split():\n",
    "        if all(l in word.lower() for l in letters): # could optimize with sets if needed\n",
    "            list1.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find species type\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getSpecies(URL):\n",
    "# URL = \"http://www.inaturalist.org/photos/1569526\"\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(id=\"wrapper\")\n",
    "    job_elements = results.find_all(\"div\", class_=\"readable species_guess attribute\")\n",
    "    for job_element in job_elements:\n",
    "        title_element = job_element.find(\"span\", class_=\"sciname\")\n",
    "        species = title_element.text\n",
    "        species = species.replace(\" \", \"_\")\n",
    "    return species\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dont know what this does \n",
    "from bs4 import BeautifulSoup as BSHTML\n",
    "import urllib\n",
    "import requests # to get image from the web\n",
    "import shutil # to save it locally\n",
    "\n",
    "# direct image file url \n",
    "def url_link(URL):\n",
    "    code = URL.find('/photos/')\n",
    "    code = URL[code+8:]\n",
    "    page = urllib.request.urlopen(URL)\n",
    "    soup = BSHTML(page)\n",
    "    images = soup.findAll('img')\n",
    "\n",
    "    for image in images:\n",
    "        image_name = image['src']\n",
    "        if image_name.startswith('https://inaturalist-open-data.s3.amazonaws.com/photos/'+code+'/medium'):\n",
    "            return image_name\n",
    "\n",
    "# download image from direct url \n",
    "def download_image(image_url):\n",
    "    filename = image_url.split(\"s/\")[-1]\n",
    "    filename = filename.replace('/medium',\"\")\n",
    "    filename = 'image_dataset/' + filename\n",
    "\n",
    "    r = requests.get(image_url, stream = True)\n",
    "    r.raw.decode_content = True\n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    with open(filename,'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING ONE\n",
    "def download_image(URL):\n",
    "    code = URL.find('/photos/')\n",
    "    code = URL[code+8:]\n",
    "    code = code.rsplit('/o', 1)[0]\n",
    "\n",
    "    if URL.find('.jpg') != -1:\n",
    "        is_jpg = True\n",
    "    else:\n",
    "        is_jpg = False\n",
    "\n",
    "    image_url_jpg = 'https://inaturalist-open-data.s3.amazonaws.com/photos/'+code+'/medium.jpg'\n",
    "    image_url_jpeg = 'https://inaturalist-open-data.s3.amazonaws.com/photos/'+code+'/medium.jpeg' \n",
    "    \n",
    "    if is_jpg == True:\n",
    "        filename = image_url_jpg.split(\"s/\")[-1]\n",
    "        filename = filename.replace('/medium.jpg',\"\")\n",
    "        filename = 'image_dataset/' + filename + '.jpg'\n",
    "        r = requests.get(image_url_jpg, stream = True)\n",
    "    else: \n",
    "        filename = image_url_jpeg.split(\"s/\")[-1]\n",
    "        filename = filename.replace('/medium.jpeg',\"\")\n",
    "        filename = 'image_dataset/' + filename + '.jpeg'\n",
    "        r = requests.get(image_url_jpeg, stream = True)\n",
    "\n",
    "    species_name = getSpecies(URL)\n",
    "    filename = species_name + \"_\" + filename\n",
    "    r.raw.decode_content = True\n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    with open(filename,'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for URL in list1:\n",
    "    download_image(URL) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for URL, URL2 in zip(list1, list):\n",
    "    code = URL.find('/photos/')\n",
    "    code = URL[code+8:]\n",
    "    code = code.rsplit('/o', 1)[0]\n",
    "\n",
    "    if URL.find('.jpg') != -1:\n",
    "        is_jpg = True\n",
    "    else:\n",
    "        is_jpg = False\n",
    "\n",
    "    image_url_jpg = 'https://inaturalist-open-data.s3.amazonaws.com/photos/'+code+'/medium.jpg'\n",
    "    image_url_jpeg = 'https://inaturalist-open-data.s3.amazonaws.com/photos/'+code+'/medium.jpeg' \n",
    "    \n",
    "    if is_jpg == True:\n",
    "        filename = image_url_jpg.split(\"s/\")[-1]\n",
    "        filename = filename.replace('/medium.jpg',\"\")\n",
    "        filename = 'image_dataset/' + filename + '.jpg'\n",
    "        r = requests.get(image_url_jpg, stream = True)\n",
    "    else: \n",
    "        filename = image_url_jpeg.split(\"s/\")[-1]\n",
    "        filename = filename.replace('/medium.jpeg',\"\")\n",
    "        filename = 'image_dataset/' + filename + '.jpeg'\n",
    "        r = requests.get(image_url_jpeg, stream = True)\n",
    "    \n",
    "    species_name = getSpecies(URL2)\n",
    "    filename = filename[:14] + species_name + \"-\" + filename[14:]\n",
    "    r.raw.decode_content = True\n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    with open(filename,'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occurrence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_occurence =[]\n",
    "x = open(\"occurrence.txt\", \"r\")\n",
    "\n",
    "letters = \"https://www.inaturalist.org/observations/\"\n",
    "for line in x:\n",
    "    for word in line.split():\n",
    "        if all(l in word.lower() for l in letters): # could optimize with sets if needed\n",
    "            list_occurence.append(word)\n",
    "\n",
    "letters = \"https://bugguide.net/node/view/\"\n",
    "for line in x:\n",
    "    for word in line.split():\n",
    "        if all(l in word.lower() for l in letters): # could optimize with sets if needed\n",
    "            list_occurence.append(word)\n",
    "\n",
    "# letters = \"https://www.inaturalist.org/observations/\"\n",
    "# for line in x:\n",
    "#     for word in line.split():\n",
    "#         if all(l in word.lower() for l in letters): # could optimize with sets if needed\n",
    "#             list_occurence.append(word)\n",
    "\n",
    "print(list_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    " \n",
    "# Making a GET request\n",
    "def getIMGPath(URL): \n",
    "\n",
    "    r = requests.get(URL)\n",
    "    \n",
    "    # Parsing the HTML\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    page = str(soup)\n",
    "    start = page.find('https://inaturalist-open-data.s3.amazonaws.com/photos/')\n",
    "    end = page.find(' property=\"og:image\"')\n",
    "    path = page[start:end]\n",
    "    path = path.removesuffix('\"')\n",
    "\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "def getSpecies(line):\n",
    "\n",
    "    if line.find('Amblyomma_americanum') != -1:\n",
    "        return 'Amblyomma_americanum'\n",
    "    elif line.find('Dermacentor_variabilis') != -1:\n",
    "        return 'Dermacentor_variabilis'\n",
    "    else: \n",
    "        return 'Ixodes_scapularis'\n",
    "\n",
    "def getQuality(line):\n",
    "    \n",
    "    if line.find('Discard') != -1: \n",
    "        return 'Discard'\n",
    "    elif line.find('Augment') != -1:\n",
    "        return 'Augment'\n",
    "    else:\n",
    "        return 'Keep'\n",
    "\n",
    "def getRTS(line):\n",
    "\n",
    "    index_start = find_nth(line, ',', 2)\n",
    "    index_end = find_nth(line, ',', 3)\n",
    "    return 'RTS_' + line[index_start+1:index_end]\n",
    "\n",
    "def getLifeStage(line):\n",
    "\n",
    "    index_start = find_nth(line, ',', 5)\n",
    "    index_end = find_nth(line, ',', 6)\n",
    "    return 'life_' + line[index_start+1:index_end]\n",
    "\n",
    "def getSex(line):\n",
    "\n",
    "    index_start = find_nth(line, ',', 4)\n",
    "    index_end = find_nth(line, ',', 5)\n",
    "    return 'sex_' + line[index_start+1:index_end]\n",
    "   \n",
    "def getFeedingStatus(line):\n",
    "\n",
    "    if line.find('fed') != -1:\n",
    "        return 'fed'\n",
    "    elif line.find('unfed') != -1:\n",
    "        return 'unfed'\n",
    "    else:\n",
    "        return 'feed_unk'\n",
    "\n",
    "original_filename = \"lennijusten.txt\"\n",
    "imgID_list = []\n",
    "\n",
    "with open(original_filename) as file_in:\n",
    "    lines = []\n",
    "    for line in file_in:\n",
    "        lines.append(line)\n",
    "\n",
    "for line in lines:\n",
    "\n",
    "    species = getSpecies(line)\n",
    "    quality = getQuality(line)\n",
    "    rts = getRTS(line)\n",
    "    lifeStage = getLifeStage(line)\n",
    "    feedStatus = getFeedingStatus(line)\n",
    "\n",
    "    filenum_start = find_nth(line, '_', 7)\n",
    "    filenum_end = line.find(\".\")\n",
    "    filenum = line[filenum_start+1:filenum_end]\n",
    "\n",
    "    filename = str(filenum) + \"+\" + species + \"+\" + quality + \"+\" + rts + \"+\" + lifeStage + \"+\" + feedStatus\n",
    "    imgID_list.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "existingFiles = []\n",
    "for file in glob.iglob('/Volumes/My Passport/*'):\n",
    "    if file.startswith('/Volumes/My Passport/tickImages'):\n",
    "        file = file.removeprefix('/Volumes/My Passport/tickImages/tickImages')\n",
    "    else:\n",
    "        file = file.removeprefix('/Volumes/My Passport/tickImages/tick_images')\n",
    "    remove_part = file.find(\"+\")\n",
    "    end = len(file)\n",
    "    file = file.removesuffix(file[remove_part:end])\n",
    "    existingFiles.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path \n",
    "import time \n",
    "path_list = []\n",
    "for id in imgID_list:\n",
    "    remove_part = id.find(\"+\")\n",
    "    end = len(id)\n",
    "    num = id.removesuffix(id[remove_part:end])\n",
    "    if any(num in word for word in existingFiles) == False: # delete this in the future; just to pick up where left off\n",
    "        path = 'https://www.inaturalist.org/observations/'+num\n",
    "        if num.find(\"-\") == -1 and num.find(\"_\") == -1: # if num > 4:\n",
    "            absolute_path = getIMGPath(path)\n",
    "            if absolute_path != \"\":      \n",
    "                r = requests.get(absolute_path, stream = True)\n",
    "                r.raw.decode_content = True\n",
    "                filename = '/Volumes/My Passport/tickImages'+id+'.jpg'\n",
    "                with open(filename,'wb') as f:\n",
    "                    shutil.copyfileobj(r.raw, f)\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for file in glob.iglob('/Volumes/My Passport/*'):\n",
    "    if file.startswith('/Volumes/My Passport/tick_images'):\n",
    "        newName = file.removeprefix('/Volumes/My Passport/tick_images')\n",
    "        newName = '/Volumes/My Passport/' + newName\n",
    "        os.rename(file, newName)\n",
    "    elif file.startswith('/Volumes/My Passport/tickImages'):\n",
    "        newName = file.removeprefix('/Volumes/My Passport/tickImages')\n",
    "        newName = '/Volumes/My Passport/' + newName\n",
    "        os.rename(file, newName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4973\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "count = 0\n",
    "for file in glob.iglob('/Volumes/My Passport/*'):\n",
    "    count +=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
